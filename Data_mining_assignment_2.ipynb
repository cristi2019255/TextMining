{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_mining_assignment_2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "S8vHp7KYWQ9J",
        "LKvgQaWrHtTQ"
      ],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cristi2019255/TextMining/blob/main/Data_mining_assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "O955y5BuV7Ry"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVSXm3cDlfFP",
        "outputId": "74c27bf7-8a87-4ca9-bbba-7eb9005ab030"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdtkNDgYHtTK"
      },
      "source": [
        "import os\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooZ3imL3HtTL",
        "outputId": "b054745e-3532-4e34-a412-6f542c896272"
      },
      "source": [
        "!{sys.executable} -m pip install nltk sklearn scipy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: {sys.executable}: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK7UD6r7HtTM"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.probability import FreqDist\n",
        "from sklearn.model_selection import KFold, GridSearchCV, cross_val_score, train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk import word_tokenize, pos_tag          \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from sklearn.metrics import classification_report\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4cF_94THtTM"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "from sklearn.feature_selection import mutual_info_classif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "jPWplk-kv4Vj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2WkFsw3HtTR"
      },
      "source": [
        "def evaluate_pred(Y_test, Y_pred):            \n",
        "    print(\"Number of mislabeled points out of a total %d points : %d\"\n",
        "       % (len(Y_test), (Y_test != Y_pred).sum()))    \n",
        "    print('acc: ', accuracy_score(Y_test, Y_pred))\n",
        "    print('precision: ', precision_score(Y_test,Y_pred))\n",
        "    print('recall: ', recall_score(Y_test,Y_pred))\n",
        "    print('F: ', f1_score(Y_test,Y_pred))\n",
        "    return accuracy_score(Y_test, Y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "fdngbsMpV_ho"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMpPEUktHtTN"
      },
      "source": [
        "# first load in the reviews into a corpus\n",
        "def get_corpus(data_path):\n",
        "    corpus, Y = [], []    \n",
        "    file_nr = 0\n",
        "    '''reads all thruthful negative reviews, prepares the text, and adds it to the corpus'''    \n",
        "    for review_type in ['deceptive_from_MTurk', 'truthful_from_Web']:              \n",
        "        for fold in ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']:            \n",
        "            for file in os.listdir(os.path.join(data_path, review_type , fold)):\n",
        "                file_path = os.path.join(data_path, review_type, fold, file)\n",
        "                \n",
        "                # open review\n",
        "                with open(file_path, \"r\") as f:\n",
        "                    raw_review = f.read()                  \n",
        "                corpus.append(raw_review)\n",
        "                file_nr +=1\n",
        "                if (file_nr % 100 == 0):\n",
        "                  print(file_nr)                \n",
        "                Y.append(0 if review_type == 'deceptive_from_MTurk' else 1)                                 \n",
        "    return corpus, Y\n",
        "\n",
        "# defining stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# defining lemmatization \n",
        "class LemmaTokenizer(object):\n",
        "    def __init__(self):\n",
        "        self.wnl = WordNetLemmatizer()\n",
        "    def __call__(self, review):\n",
        "        review = review.translate(str.maketrans(\"\",\"\", string.punctuation)) # remove punctuation\n",
        "        review = re.sub(r'\\d+', '', review) # remove numbers\n",
        "        return [self.wnl.lemmatize(token) for token in word_tokenize(review) if token not in stop_words]\n",
        "\n",
        "# defining steamming\n",
        "class SteammingTokenizer(object):\n",
        "    def __init__(self):\n",
        "        self.stemmer = PorterStemmer()        \n",
        "    def __call__(self, review):\n",
        "        review = review.translate(str.maketrans(\"\",\"\", string.punctuation)) # remove punctuation\n",
        "        review = re.sub(r'\\d+', '', review) # remove numbers\n",
        "        return [self.stemmer.stem(token) for token in word_tokenize(review) if token not in stop_words]\n",
        "\n",
        "# defining POS\n",
        "class POSTokenizer(object):\n",
        "    def __init__(self, lemmatizer = False, select = False):         \n",
        "        self.wnl = WordNetLemmatizer() \n",
        "        self.lemmatization = lemmatizer \n",
        "        self.select = select\n",
        "    def __call__(self, review):        \n",
        "        review = review.translate(str.maketrans(\"\",\"\", string.punctuation)) # remove punctuation\n",
        "        review = re.sub(r'\\d+', '', review) # remove numbers\n",
        "        tokens = [token for token in pos_tag(word_tokenize(review)) if token[0] not in stop_words]                                \n",
        "        if self.select:\n",
        "          return [token[0]+\" \"+token[1] for token in tokens if (('NN' in token[1])or('VB' in token[1])) ]\n",
        "        if self.lemmatization:          \n",
        "          tokens = [self.wnl.lemmatize(token[0])+\" \"+token[1] for token in tokens]          \n",
        "        else:\n",
        "          tokens = [token[0]+\" \"+token[1] for token in tokens]\n",
        "        return tokens\n",
        "\n",
        "\n",
        "# getting the words frequences\n",
        "def vectorize(corpus, n_grams = 2, min_df = 0.01, max_df = 0.95, method='lemmatize'):  \n",
        "  dictionary = {\n",
        "      'lemmatize': LemmaTokenizer(),\n",
        "      'stemming':  SteammingTokenizer(),\n",
        "      'pos': POSTokenizer(),\n",
        "      'pos_lemmatize': POSTokenizer(lemmatizer = True),\n",
        "      'pos_select': POSTokenizer(select=True),\n",
        "      'tokenizer': RegexpTokenizer(r'[a-zA-Z]+').tokenize # to remove unwanted elements from out data like symbols and numbers\n",
        "  }  \n",
        "  tokenizer = dictionary[method]\n",
        "\n",
        "  vectorizer = TfidfVectorizer(\n",
        "                               lowercase=True,\n",
        "                               ngram_range = (1,n_grams),                              \n",
        "                               tokenizer = tokenizer, \n",
        "                               min_df = min_df, #remove terms with minimum document frequency as known as removing sparse terms\n",
        "                               max_df= max_df #remove most frequent terms as they might be not interesting\n",
        "                               )\n",
        "  X = vectorizer.fit_transform(corpus).toarray()\n",
        "  feature_names = vectorizer.get_feature_names_out()\n",
        "  return X, feature_names\n",
        "\n",
        "  \n",
        "## running to long need to be imporved\n",
        "def mutual_info_feature_selection(X, Y, feature_names, trashold=0.01, top_k=300, method='top'):    \n",
        "  mutual_info = mutual_info_classif(X, Y, random_state=0)  \n",
        "  print(len(mutual_info))\n",
        "  if method == 'top':      \n",
        "    top_values = list(mutual_info)\n",
        "    top_values.sort()\n",
        "    top_values = top_values[::-1][:top_k] # ordering descending and taking best k\n",
        "    feature_indx = [True if (mutual_info[i] in top_values) else False for i in range(len(mutual_info))]\n",
        "  else:\n",
        "    feature_indx = mutual_info > trashold  \n",
        "  return X[:,feature_indx], feature_indx, mutual_info[feature_indx]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvsNDhodHtTN",
        "outputId": "85d94c51-64cc-4dfc-f739-43864425d88c"
      },
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/Data_mining_assignment_2021_2/op_spam_v1.4/negative_polarity\"\n",
        "corpus, Y = get_corpus(DATA_PATH)\n",
        "X, feature_names = vectorize(corpus, method='pos', n_grams=1)\n",
        "print(feature_names)\n",
        "print(len(feature_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "['able JJ' 'absolutely RB' 'ac NN' ... 'yet RB' 'young JJ' 'youre NN']\n",
            "1351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used for testing what preprocess technique is the best\n",
        "naive_bayes = MultinomialNB().fit(X, Y)\n",
        "Y_pred = naive_bayes.predict(X)\n",
        "print(accuracy_score(Y_pred,Y))"
      ],
      "metadata": {
        "id": "f5Az8ISwhu6O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff2f6b21-b68f-4a61-d4af-27a58b02c571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.96125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature selection"
      ],
      "metadata": {
        "id": "S8vHp7KYWQ9J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73X4koy87Uny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af31d1bc-364d-4c14-db7d-a9d18070447a"
      },
      "source": [
        "X_mutual, feature_indx, info_values = mutual_info_feature_selection(X, Y, feature_names, method='percentage', trashold=0.005)\n",
        "feature_selected = np.array(feature_names)[np.array(feature_indx)]\n",
        "feature_names = np.array(feature_names)[np.array(feature_indx)]\n",
        "print('selected nr of features: ',len(feature_selected))\n",
        "print(feature_selected[:10])\n",
        "X = X_mutual.copy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1351\n",
            "selected nr of features:  562\n",
            "['absolutely RB' 'access NN' 'accommodations NNS' 'actual JJ' 'advance NN'\n",
            " 'affinia JJ' 'affinia NN' 'afternoon NN' 'ago IN' 'allowed VBN']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Used for testing what feature extration technique is the best\n",
        "naive_bayes = MultinomialNB().fit(X_mutual, Y)\n",
        "Y_pred = naive_bayes.predict(X_mutual)\n",
        "print(accuracy_score(Y_pred,Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG8lLV2r9AfZ",
        "outputId": "c1494d53-1f61-45b6-b422-e81b446ab245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.91375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# spliting into train and test: fold5 for test others for training and parameter tuning\n",
        "\n",
        "n = len(X)\n",
        "X_train = np.concatenate((X[:int(n*0.4)],X[int(n*0.5):int(n*0.9)]))\n",
        "X_test = np.concatenate((X[int(n*0.4):int(n*0.5)], X[int(n*0.9):]))\n",
        "Y_train, Y_test = Y[:int(n*0.4)] + Y[int(n*0.5):int(n*0.9)], Y[int(n*0.4):int(n*0.5)] + Y[int(n*0.9):]\n",
        "\n",
        "\n",
        "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8,random_state=0)"
      ],
      "metadata": {
        "id": "2qV7WMYJraSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Used for testing what preprocess technique is the best\n",
        "naive_bayes = MultinomialNB().fit(X_train, Y_train)\n",
        "Y_pred = naive_bayes.predict(X_test)\n",
        "print(accuracy_score(Y_pred,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHHvZ1aUs9X3",
        "outputId": "dcae467f-c80c-4b74-8aa2-0eccb84f8890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKvgQaWrHtTQ"
      },
      "source": [
        "# Use Cross-Validation to select the best hyperparameters!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTjjpnkqUTkb"
      },
      "source": [
        "cv = 5\n",
        "\n",
        "def parameter_tunning_naive_baiyes(X, Y):    \n",
        "  #  To do: splitting data into 10 folders for cross validation\n",
        "  '''\n",
        "    Naive Bayes\n",
        "  '''\n",
        "  cv = KFold(5, shuffle=True, random_state=0) \n",
        "  # naive bayes has no parameters to be tunned\n",
        "  naive_bayes = MultinomialNB()\n",
        "  print(f'Cross validation for naive bayes:')\n",
        "  cross_val_scores = cross_val_score(naive_bayes, X, Y, cv=cv, n_jobs=-1)\n",
        "  print(cross_val_scores)\n",
        "  plt.plot(cross_val_scores, marker='o', linestyle=\"None\")\n",
        "\n",
        "def parameter_tunning_logistic_regresion(X, Y):    \n",
        "  '''\n",
        "    Logistic regresion\n",
        "  '''\n",
        "  # performing a Grid Search on lambda to tunne it for logistic regresion\n",
        "  C = [10**x for x in np.arange(5.0,-5.0,-0.1)]  \n",
        "  grid_search_lr = GridSearchCV(\n",
        "                      cv=cv,\n",
        "                      estimator=LogisticRegression( solver='liblinear', \n",
        "                                                    penalty='l1',\n",
        "                                                    random_state=0,                                                    \n",
        "                                                    ),\n",
        "                      param_grid={'C': C },   # C = 1/lambda                   \n",
        "                      n_jobs=-1\n",
        "                    )\n",
        "  grid_result = grid_search_lr.fit(X, Y)\n",
        "  best_lambda = grid_result.best_params_['C']\n",
        "  print(f'best lambda for logistic regresion is: {best_lambda}')\n",
        "  \n",
        "  '''\n",
        "    ploting results\n",
        "  '''\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.set_title('log lambda vs accuracy score for logistic regresion')\n",
        "  ax.set_xlabel('log lambda')\n",
        "  ax.set_ylabel('accuracy score')\n",
        "  ax.errorbar([x for x in np.arange(-5.0,5.0,0.1)], grid_result.cv_results_['mean_test_score'], yerr = grid_result.cv_results_['std_test_score'], fmt='.k', linestyle='None')\n",
        "  return best_lambda\n",
        "\n",
        "def parameter_tunning_random_forest(X, Y):    \n",
        "  '''\n",
        "    Random forest\n",
        "  '''  \n",
        "  # Grid search on Random Forest to tunne n_estimators - number of trees used and max_features\n",
        "  model = RandomForestClassifier()\n",
        "  n_estimators = [x for x in range(10,1000,10)]\n",
        "  max_features = ['sqrt', 'log2']\n",
        "  grid = {'max_features':max_features, 'n_estimators':n_estimators}\n",
        "  grid_search = GridSearchCV(\n",
        "                             estimator= RandomForestClassifier(),\n",
        "                             param_grid=grid, \n",
        "                             n_jobs=-1, \n",
        "                             cv=cv, \n",
        "                             scoring='accuracy',\n",
        "                             error_score=0\n",
        "                             )\n",
        "  grid_result = grid_search.fit(X, Y)\n",
        "\n",
        "  # summarize results for random forest\n",
        "  max_features, n_estimators = grid_result.best_params_['max_features'], grid_result.best_params_['n_estimators']\n",
        "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "  means = grid_result.cv_results_['mean_test_score']\n",
        "  stds = grid_result.cv_results_['std_test_score']\n",
        "  params = grid_result.cv_results_['params']\n",
        "  # print(\"MEAN (STD) with: PARAMS\")\n",
        "  # for mean, stdev, param in zip(means, stds, params):\n",
        "  #  print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "  \n",
        "  '''\n",
        "    plotting results\n",
        "  '''\n",
        "  fig, ax1 = plt.subplots()\n",
        "  \n",
        "  ax1.set_title('max_features sqrt')  \n",
        "  ax1.set_xlabel('number of trees')\n",
        "  ax1.set_ylabel('accuracy score')\n",
        "  ax1.errorbar(grid['n_estimators'], grid_result.cv_results_['mean_test_score'][:len(grid['n_estimators'])],yerr = grid_result.cv_results_['std_test_score'][:len(grid['n_estimators'])] ,label= 'with max_features sqrt', fmt='.k', linestyle='None')\n",
        "  \n",
        "  fig, ax2 = plt.subplots()\n",
        "  ax2.set_title('max_features log2')  \n",
        "  ax2.set_xlabel('number of trees')\n",
        "  ax2.set_ylabel('accuracy score')\n",
        "  ax2.errorbar(grid['n_estimators'], grid_result.cv_results_['mean_test_score'][len(grid['n_estimators']):], yerr = grid_result.cv_results_['std_test_score'][len(grid['n_estimators']):], label= 'with max_features log2', fmt='.k', linestyle='None')\n",
        "  return max_features, n_estimators\n",
        "\n",
        "def parameter_tunning_decision_tree(X, Y):      \n",
        "  '''\n",
        "    Decision tree\n",
        "  '''\n",
        "  clf = DecisionTreeClassifier(random_state=0)\n",
        "  path = clf.cost_complexity_pruning_path(X, Y)\n",
        "  ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
        "  \n",
        "  betas = [math.sqrt(ccp_alphas[i]*ccp_alphas[i+1]) for i in range(len(ccp_alphas)-1)]\n",
        "  param_grid = {'ccp_alpha': betas }\n",
        "  grid_search = GridSearchCV(\n",
        "                             estimator= DecisionTreeClassifier(random_state=0),\n",
        "                             param_grid = param_grid, \n",
        "                             n_jobs=-1, \n",
        "                             cv=cv, \n",
        "                             scoring='accuracy',\n",
        "                             )\n",
        "  grid_result = grid_search.fit(X, Y)\n",
        "  best_alpha = grid_result.best_params_['ccp_alpha']\n",
        "  print(f'best aplha for decision tree cost complexity prunning is: {best_alpha}')\n",
        "  \n",
        "  '''\n",
        "    ploting results\n",
        "  '''\n",
        "  fig, ax1 = plt.subplots()    \n",
        "  ax1.set_title('alpha vs error scores')  \n",
        "  ax1.set_xlabel('alpha parameter')\n",
        "  ax1.set_ylabel('impurities')\n",
        "  ax1.step(ccp_alphas, impurities)\n",
        "\n",
        "  fig, ax2 = plt.subplots() \n",
        "  ax2.set_title('betha vs accuracy scores')\n",
        "  ax2.set_xlabel('betha parameter')\n",
        "  ax2.set_ylabel('accuracy score')  \n",
        "  ax2.errorbar(param_grid['ccp_alpha'], grid_result.cv_results_['mean_test_score'], yerr = grid_result.cv_results_['std_test_score'], fmt='.k', linestyle='None')\n",
        " \n",
        "  \n",
        "  return best_alpha  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "yLenjylHgpvZ",
        "outputId": "9d0626ae-fb05-49c8-ac6f-9715230d1edd"
      },
      "source": [
        "parameter_tunning_naive_baiyes(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross validation for naive bayes:\n",
            "[0.7890625 0.8203125 0.8203125 0.8515625 0.8203125]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "n4Dl7ADvgqeI",
        "outputId": "48a0a057-b447-41a9-d595-653b5a56d684"
      },
      "source": [
        "best_lambda = parameter_tunning_logistic_regresion(X_train, Y_train)\n",
        "# best lambda for logistic regresion is: 39810.71705534986"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best lambda for logistic regresion is: 19952.62314968891\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQJ-Ew4FgqY4"
      },
      "source": [
        "max_features, n_estimators = parameter_tunning_random_forest(X_train, Y_train)\n",
        "# Best: 0.870000 using {'max_features': 'log2', 'n_estimators': 730}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-5xufOMgqKI"
      },
      "source": [
        "alpha = parameter_tunning_decision_tree(X_train, Y_train)\n",
        "# best aplha for decision tree cost complexity prunning is: 0.01516109606759828"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j50qt-qtgtpA"
      },
      "source": [
        "parameters = {'lambda': best_lambda, 'max_features': max_features, 'n_estimators': n_estimators, 'alpha': alpha}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the most confident features\n",
        "logistic_regression = LogisticRegression(\n",
        "                                          random_state=0,\n",
        "                                          solver='liblinear', \n",
        "                                          penalty='l1',\n",
        "                                          C = parameters['lambda']\n",
        "                                          ).fit(X_train, Y_train)\n",
        "Y_pred = logistic_regression.predict(X_test)\n",
        "print(f'acc: {accuracy_score(Y_pred,Y_test)}')\n",
        "weights = logistic_regression.coef_[0].tolist()\n",
        "features_0 = []\n",
        "features_1 = []\n",
        "for i in range(10):\n",
        "  max = np.max(weights)\n",
        "  min = np.min(weights)\n",
        "  features_0.append(feature_names[weights.index(max)])\n",
        "  features_1.append(feature_names[weights.index(min)])\n",
        "  weights.remove(max)\n",
        "  weights.remove(min)\n",
        "print(features_0, 'top for truthful')\n",
        "print(features_1, 'top for deceptive')\n"
      ],
      "metadata": {
        "id": "Q8B_OYPGOmhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing models\n"
      ],
      "metadata": {
        "id": "byVqs_cCgFgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrained params in order to skip cross validation\n",
        "parameters = {\n",
        "              'lambda':39810.71705534986,\n",
        "              'max_features': 'log2', \n",
        "              'n_estimators': 730, \n",
        "              'alpha': 0.01516109606759828\n",
        "              }"
      ],
      "metadata": {
        "id": "RFm1EyHMzVSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes = MultinomialNB().fit(X_train, Y_train)\n",
        "\n",
        "logistic_regression = LogisticRegression(\n",
        "                                          random_state=0,\n",
        "                                          solver='liblinear', \n",
        "                                          penalty='l1',\n",
        "                                          C = parameters['lambda']\n",
        "                                          ).fit(X_train, Y_train)\n",
        "\n",
        "decision_tree = DecisionTreeClassifier(\n",
        "                                        random_state=0,\n",
        "                                        ccp_alpha=parameters['alpha']\n",
        "                                        ).fit(X_train,Y_train)\n",
        "\n",
        "random_forest = RandomForestClassifier(\n",
        "                                        max_features=parameters['max_features'],\n",
        "                                        n_estimators = parameters['n_estimators'],\n",
        "                                        random_state=0\n",
        "                                        ).fit(X_train,Y_train)\n",
        "\n",
        "# predicting\n",
        "Y_pred = naive_bayes.predict(X_test)\n",
        "print(f'Naive Bayes')\n",
        "evaluate_pred(Y_test, Y_pred)\n",
        "\n",
        "Y_pred = logistic_regression.predict(X_test)  \n",
        "print(f'Logistic Regression')\n",
        "evaluate_pred(Y_test, Y_pred)\n",
        "\n",
        "Y_pred = decision_tree.predict(X_test)\n",
        "print(f'Decision tree')\n",
        "evaluate_pred(Y_test, Y_pred)\n",
        "\n",
        "Y_pred = random_forest.predict(X_test)\n",
        "print(f'Random Forest')\n",
        "evaluate_pred(Y_test, Y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2NexmOBgIu_",
        "outputId": "78c071cc-c5aa-4477-ead2-fb7bd062faa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes\n",
            "Number of mislabeled points out of a total 160 points : 36\n",
            "acc:  0.775\n",
            "precision:  0.7972972972972973\n",
            "recall:  0.7375\n",
            "F:  0.7662337662337663\n",
            "Logistic Regression\n",
            "Number of mislabeled points out of a total 160 points : 45\n",
            "acc:  0.71875\n",
            "precision:  0.7272727272727273\n",
            "recall:  0.7\n",
            "F:  0.7133757961783439\n",
            "Decision tree\n",
            "Number of mislabeled points out of a total 160 points : 50\n",
            "acc:  0.6875\n",
            "precision:  0.6704545454545454\n",
            "recall:  0.7375\n",
            "F:  0.7023809523809523\n",
            "Random Forest\n",
            "Number of mislabeled points out of a total 160 points : 36\n",
            "acc:  0.775\n",
            "precision:  0.782051282051282\n",
            "recall:  0.7625\n",
            "F:  0.7721518987341772\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.775"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcxcHbuzcJ7d"
      },
      "source": [
        "# Test on fold5 to see final evaluation scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UZUSnXIHtTQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0ccb5f-8658-4b40-ec8e-eb5c98bf9585"
      },
      "source": [
        "# Splitting into train and test after fold5\n",
        "'''\n",
        "We need to create 5x2 CV\n",
        "so 5 times 50% split\n",
        "'''\n",
        "res_NB = []\n",
        "res_LR = []\n",
        "res_DT = []\n",
        "res_RF = []\n",
        "for i in range (5):\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, shuffle=True)\n",
        "\n",
        "  naive_bayes = MultinomialNB().fit(X_train, Y_train)\n",
        "\n",
        "  logistic_regression = LogisticRegression(\n",
        "                                          random_state=0,\n",
        "                                          solver='liblinear', \n",
        "                                          penalty='l1',\n",
        "                                          C = parameters['lambda']\n",
        "                                          ).fit(X_train, Y_train)\n",
        "\n",
        "  decision_tree = DecisionTreeClassifier(\n",
        "                                        random_state=0,\n",
        "                                        ccp_alpha=parameters['alpha']\n",
        "                                        ).fit(X_train,Y_train)\n",
        "\n",
        "  random_forest = RandomForestClassifier(\n",
        "                                        max_features=parameters['max_features'],\n",
        "                                        n_estimators = parameters['n_estimators'],\n",
        "                                        random_state=0\n",
        "                                        ).fit(X_train,Y_train)\n",
        "\n",
        "  Y_pred = naive_bayes.predict(X_test)\n",
        "  print(f'Naive Bayes')\n",
        "  res_NB.append(evaluate_pred(Y_test, Y_pred))\n",
        "\n",
        "  Y_pred = logistic_regression.predict(X_test)\n",
        "  # print(Y_pred)\n",
        "  print(f'Logistic Regression')\n",
        "  res_LR.append(evaluate_pred(Y_test, Y_pred))\n",
        "\n",
        "  Y_pred = decision_tree.predict(X_test)\n",
        "  print(f'Decision tree')\n",
        "  res_DT.append(evaluate_pred(Y_test, Y_pred))\n",
        "\n",
        "  Y_pred = random_forest.predict(X_test)\n",
        "  print(f'Random Forest')\n",
        "  res_RF.append(evaluate_pred(Y_test, Y_pred))\n",
        "\n",
        "print(res_NB)\n",
        "print(res_LR)\n",
        "print(res_DT)\n",
        "print(res_RF)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes\n",
            "Number of mislabeled points out of a total 400 points : 70\n",
            "acc:  0.825\n",
            "precision:  0.8369565217391305\n",
            "recall:  0.7938144329896907\n",
            "F:  0.8148148148148148\n",
            "Logistic Regression\n",
            "Number of mislabeled points out of a total 400 points : 79\n",
            "acc:  0.8025\n",
            "precision:  0.7804878048780488\n",
            "recall:  0.8247422680412371\n",
            "F:  0.8020050125313283\n",
            "Decision tree\n",
            "Number of mislabeled points out of a total 400 points : 134\n",
            "acc:  0.665\n",
            "precision:  0.6376146788990825\n",
            "recall:  0.7164948453608248\n",
            "F:  0.674757281553398\n",
            "Random Forest\n",
            "Number of mislabeled points out of a total 400 points : 76\n",
            "acc:  0.81\n",
            "precision:  0.7633928571428571\n",
            "recall:  0.8814432989690721\n",
            "F:  0.818181818181818\n",
            "Naive Bayes\n",
            "Number of mislabeled points out of a total 400 points : 104\n",
            "acc:  0.74\n",
            "precision:  0.921875\n",
            "recall:  0.5566037735849056\n",
            "F:  0.6941176470588236\n",
            "Logistic Regression\n",
            "Number of mislabeled points out of a total 400 points : 83\n",
            "acc:  0.7925\n",
            "precision:  0.837696335078534\n",
            "recall:  0.7547169811320755\n",
            "F:  0.794044665012407\n",
            "Decision tree\n",
            "Number of mislabeled points out of a total 400 points : 125\n",
            "acc:  0.6875\n",
            "precision:  0.6653992395437263\n",
            "recall:  0.8254716981132075\n",
            "F:  0.736842105263158\n",
            "Random Forest\n",
            "Number of mislabeled points out of a total 400 points : 83\n",
            "acc:  0.7925\n",
            "precision:  0.837696335078534\n",
            "recall:  0.7547169811320755\n",
            "F:  0.794044665012407\n",
            "Naive Bayes\n",
            "Number of mislabeled points out of a total 400 points : 80\n",
            "acc:  0.8\n",
            "precision:  0.8903225806451613\n",
            "recall:  0.6865671641791045\n",
            "F:  0.7752808988764045\n",
            "Logistic Regression\n",
            "Number of mislabeled points out of a total 400 points : 92\n",
            "acc:  0.77\n",
            "precision:  0.7632850241545893\n",
            "recall:  0.7860696517412935\n",
            "F:  0.7745098039215685\n",
            "Decision tree\n",
            "Number of mislabeled points out of a total 400 points : 132\n",
            "acc:  0.67\n",
            "precision:  0.6604651162790698\n",
            "recall:  0.7064676616915423\n",
            "F:  0.6826923076923076\n",
            "Random Forest\n",
            "Number of mislabeled points out of a total 400 points : 89\n",
            "acc:  0.7775\n",
            "precision:  0.788659793814433\n",
            "recall:  0.7611940298507462\n",
            "F:  0.7746835443037974\n",
            "Naive Bayes\n",
            "Number of mislabeled points out of a total 400 points : 60\n",
            "acc:  0.85\n",
            "precision:  0.8164251207729468\n",
            "recall:  0.8848167539267016\n",
            "F:  0.8492462311557789\n",
            "Logistic Regression\n",
            "Number of mislabeled points out of a total 400 points : 72\n",
            "acc:  0.82\n",
            "precision:  0.8181818181818182\n",
            "recall:  0.8010471204188482\n",
            "F:  0.8095238095238095\n",
            "Decision tree\n",
            "Number of mislabeled points out of a total 400 points : 125\n",
            "acc:  0.6875\n",
            "precision:  0.6299212598425197\n",
            "recall:  0.837696335078534\n",
            "F:  0.7191011235955056\n",
            "Random Forest\n",
            "Number of mislabeled points out of a total 400 points : 70\n",
            "acc:  0.825\n",
            "precision:  0.7951219512195122\n",
            "recall:  0.8534031413612565\n",
            "F:  0.8232323232323233\n",
            "Naive Bayes\n",
            "Number of mislabeled points out of a total 400 points : 77\n",
            "acc:  0.8075\n",
            "precision:  0.8538011695906432\n",
            "recall:  0.7373737373737373\n",
            "F:  0.7913279132791328\n",
            "Logistic Regression\n",
            "Number of mislabeled points out of a total 400 points : 92\n",
            "acc:  0.77\n",
            "precision:  0.7944444444444444\n",
            "recall:  0.7222222222222222\n",
            "F:  0.7566137566137566\n",
            "Decision tree\n",
            "Number of mislabeled points out of a total 400 points : 128\n",
            "acc:  0.68\n",
            "precision:  0.65625\n",
            "recall:  0.7424242424242424\n",
            "F:  0.6966824644549764\n",
            "Random Forest\n",
            "Number of mislabeled points out of a total 400 points : 77\n",
            "acc:  0.8075\n",
            "precision:  0.8040201005025126\n",
            "recall:  0.8080808080808081\n",
            "F:  0.8060453400503778\n",
            "[0.825, 0.74, 0.8, 0.85, 0.8075]\n",
            "[0.8025, 0.7925, 0.77, 0.82, 0.77]\n",
            "[0.665, 0.6875, 0.67, 0.6875, 0.68]\n",
            "[0.81, 0.7925, 0.7775, 0.825, 0.8075]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stats.ttest_rel(res_NB, res_DT).pvalue)\n",
        "print(stats.ttest_rel(res_NB, res_LR).pvalue)\n",
        "print(stats.ttest_rel(res_NB, res_RF).pvalue)\n",
        "print(stats.ttest_rel(res_DT, res_LR).pvalue)\n",
        "print(stats.ttest_rel(res_DT, res_RF).pvalue)\n",
        "print(stats.ttest_rel(res_LR, res_RF).pvalue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ke3u_A0qk1E",
        "outputId": "3faa7de2-059a-4856-8bb8-8adaf7d8d179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0031293609247162128\n",
            "0.4634470834106993\n",
            "0.8955643662134358\n",
            "0.00026706796810035824\n",
            "9.762560555621551e-05\n",
            "0.15845392703924577\n"
          ]
        }
      ]
    }
  ]
}